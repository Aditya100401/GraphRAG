{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALL AGENTING PIPELINES LIKE REACT AND REFLEXTION AGENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import datetime\n",
    "import os\n",
    "from groq import Groq\n",
    "from dotenv import load_dotenv\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('KG/new_graph.pkl', 'rb') as f:\n",
    "    G = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def search_news(actor, recipient):\n",
    "    query = f\"{actor} and Congress\"\n",
    "    api_key = \"fb8156f456be4094b9e88dd55b1d29fa\" # Replace with your API key\n",
    "    url = f\"https://newsapi.org/v2/everything?q={query}&sortBy=publishedAt&apiKey={api_key}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        articles = response.json().get('articles', [])\n",
    "        return [{\"title\": article['title'], \"description\": article['description'], \"url\": article['url']} for article in articles[:1]]\n",
    "    else:\n",
    "        print(f\"Error fetching news articles: {response.status_code}, {response.text}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_node_edge_connections(graph, actor, recipient, date):\n",
    "    relevant_edges = []\n",
    "    relevant_nodes = set()\n",
    "    for u, v, data in graph.edges(data=True):\n",
    "        if (actor in [u, v] or recipient in [u, v]) and data.get('relation') == 'event':\n",
    "            event_date = graph.nodes[u].get('event_date', graph.nodes[v].get('event_date'))\n",
    "            if event_date and datetime.datetime.strptime(event_date, \"%Y-%m-%d\") < datetime.datetime.strptime(date, \"%Y-%m-%d\"):\n",
    "                relevant_edges.append((u, v, data))\n",
    "                relevant_nodes.add(u)\n",
    "                relevant_nodes.add(v)\n",
    "    return relevant_nodes, relevant_edges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_node_attributes(graph, actor, recipient, input_date):\n",
    "    # Convert input_date to datetime object for comparison\n",
    "    input_date = datetime.strptime(input_date, \"%Y-%m-%d\")\n",
    "\n",
    "    # Create a list to store the events that match the criteria\n",
    "    matching_events = []\n",
    "\n",
    "    # Iterate through all nodes in the graph\n",
    "    for node in graph.nodes:\n",
    "        # Check if the node has event_id attribute and is an event node\n",
    "        if 'event_date' in graph.nodes[node]:\n",
    "            # Get the event date and check if actor and recipient match\n",
    "            event_date = datetime.strptime(graph.nodes[node]['event_date'], \"%Y-%m-%d\")\n",
    "            \n",
    "            # Find the actor and recipient neighbors\n",
    "            actor_neighbors = list(graph.neighbors(node))\n",
    "            recipient_neighbors = list(graph.neighbors(node))\n",
    "            \n",
    "            if actor in actor_neighbors and recipient in recipient_neighbors:\n",
    "                # Calculate the time difference between input date and event date\n",
    "                time_diff = abs((event_date - input_date).days)\n",
    "                \n",
    "                # Append the event along with time difference to the list\n",
    "                matching_events.append((node, time_diff, graph.nodes[node]))\n",
    "\n",
    "    # Sort the matching events based on time difference (closest dates first)\n",
    "    matching_events.sort(key=lambda x: x[1])\n",
    "\n",
    "    # Select the top 20 events\n",
    "    top_20_events = matching_events[:5]\n",
    "\n",
    "    # Return the node attributes for the top 20 events\n",
    "    top_20_event_data = {event[0]: event[2] for event in top_20_events}\n",
    "    return top_20_event_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_event_type_frequency(graph, actor, recipient, date):\n",
    "    event_counts = {}\n",
    "    for u, v, data in graph.edges(data=True):\n",
    "        if (actor in [u, v] or recipient in [u, v]):\n",
    "            event_date = graph.nodes[u].get('event_date', graph.nodes[v].get('event_date'))\n",
    "            if event_date and datetime.strptime(event_date, \"%Y-%m-%d\") < datetime.strptime(date, \"%Y-%m-%d\"):\n",
    "                event_type = graph.nodes[u].get('event_type', graph.nodes[v].get('event_type'))\n",
    "                if event_type:\n",
    "                    event_counts[event_type] = event_counts.get(event_type, 0) + 1\n",
    "    return event_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Groq client\n",
    "client = Groq(api_key=os.getenv(\"GROQ_API_KEY\"))\n",
    "\n",
    "def query_groq_for_prediction(actor, recipient, date, graph):\n",
    "    # Step 1: Fetch news articles\n",
    "    news_articles = search_news(actor, recipient)\n",
    "\n",
    "    # Step 2: Extract nodes and edges\n",
    "    nodes, edges = get_node_edge_connections(graph, actor, recipient, date)\n",
    "\n",
    "    # Step 3: Output node attributes\n",
    "    node_attributes = print_node_attributes(graph, actor,recipient, date)\n",
    "\n",
    "    # Step 4: Calculate event type frequency\n",
    "    event_frequencies = calculate_event_type_frequency(graph, actor, recipient, date)\n",
    "\n",
    "    # Step 5: Create a structured prompt\n",
    "    prompt = f\"\"\"\n",
    "You are a knowledge graph analysis expert. Based on the following data, predict the most likely event type between '{actor}' and '{recipient}' on '{date}'.\n",
    "Recent News Articles:\n",
    "{news_articles}\n",
    "\n",
    "*THIS IS KNOWLEDGE GRAPH DATA FOR THE {actor} and {recipient} relations/events\n",
    "Event Frequency:\n",
    "{event_frequencies}\n",
    "\n",
    "Node Attributes:\n",
    "{node_attributes}\n",
    "\n",
    "Choose the most likely event type from the following list:\n",
    "ACCUSE, THREATEN, COERCE, SANCTION, REQUEST, ASSAULT, RETREAT, CONCEDE, MOBILIZE, PROTEST, CONSULT, AID\n",
    "\"\"\"\n",
    "    print(prompt)\n",
    "    try:\n",
    "        chat_completion = client.chat.completions.create(\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            model=\"mixtral-8x7b-32768\",\n",
    "        )\n",
    "        return chat_completion.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Error querying Groq API: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are a knowledge graph analysis expert. Based on the following data, predict the most likely event type between 'Bharatiya Janata Party' and 'Congee' on '2024-06-25'.\n",
      "Recent News Articles:\n",
      "[{'title': \"CNA Explains: What you need to know about India's 'one nation, one election' plan\", 'description': \"What would the proposal entail, and what are the benefits and drawbacks? CNA's Rohit Rajan breaks it down.\", 'url': 'https://www.channelnewsasia.com/asia/india-one-nation-one-election-cna-explains-4813646'}]\n",
      "\n",
      "*THIS IS KNOWLEDGE GRAPH DATA FOR THE Bharatiya Janata Party and Congee relations/events\n",
      "Event Frequency:\n",
      "{'PROTEST': 25, 'THREATEN': 21, 'ACCUSE': 149, 'REQUEST': 17, 'CONCEDE': 22, 'RETREAT': 22, 'MOBILIZE': 26, 'ASSAULT': 4, 'SANCTION': 23, 'COERCE': 10}\n",
      "\n",
      "Node Attributes:\n",
      "{'20240619-0830-ca901f31bcb4_ACCUSE': {'event_date': '2024-06-19', 'event_type': 'ACCUSE', 'event_intensity': -3.0, 'quad_code': 'VERBAL CONFLICT', 'contexts': 'election '}, '20240619-5134-c522fb30767d_MOBILIZE': {'event_date': '2024-06-19', 'event_type': 'MOBILIZE', 'event_intensity': -5.5, 'quad_code': 'MATERIAL CONFLICT', 'contexts': nan}, '20240614-2886-ee89933317d7_THREATEN': {'event_date': '2024-06-14', 'event_type': 'THREATEN', 'event_intensity': -3.5, 'quad_code': 'VERBAL CONFLICT', 'contexts': 'election '}, '20240614-1244-fd0dbeb00c2f_CONCEDE': {'event_date': '2024-06-14', 'event_type': 'CONCEDE', 'event_intensity': 4.5, 'quad_code': 'VERBAL COOPERATION', 'contexts': 'election '}, '20240605-7544-22540d338429_MOBILIZE': {'event_date': '2024-06-05', 'event_type': 'MOBILIZE', 'event_intensity': -5.5, 'quad_code': 'MATERIAL CONFLICT', 'contexts': 'election '}}\n",
      "\n",
      "Choose the most likely event type from the following list:\n",
      "ACCUSE, THREATEN, COERCE, SANCTION, REQUEST, ASSAULT, RETREAT, CONCEDE, MOBILIZE, PROTEST, CONSULT, AID\n",
      "\n",
      "Predicted Event Type: Based on the given data, the most recent events between 'Bharatiya Janata Party' and 'Congee' are 'ACCUSE', 'THREATEN', and 'MOBILIZE', all in the context of 'election'. Therefore, we can infer that the events are related to election campaigns or political disputes.\n",
      "\n",
      "The event frequency shows that 'ACCUSE' is the most common event type, followed by 'MOBILIZE' and 'THREATEN'. 'CONCEDE' and 'REQUEST' are less common, while 'RETREAT', 'COERCE', 'SANCTION', 'ASSAULT', 'PROTEST', 'CONSULT', and 'AID' have not been observed at all.\n",
      "\n",
      "Therefore, based on this data, the most likely event type between 'Bharatiya Janata Party' and 'Congee' on '2024-06-25' is 'ACCUSE' or 'MOBILIZE', which are the most frequent event types in the given context. However, it is important to note that this prediction is based on historical data and may not accurately reflect future events.\n"
     ]
    }
   ],
   "source": [
    "# Define the inputs\n",
    "actor = \"Bharatiya Janata Party\"\n",
    "recipient = \"Congee\"\n",
    "date = \"2024-06-25\"\n",
    "\n",
    "# Run the prediction\n",
    "prediction = query_groq_for_prediction(actor, recipient, date, G)\n",
    "print(\"Predicted Event Type:\", prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TOOLS AND AGENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the Groq client with your API key\n",
    "client = Groq(api_key=os.getenv(\"GROQ_API_KEY\"))\n",
    "\n",
    "\n",
    "def search_and_extract_news(actor, recipient):\n",
    "    \"\"\"\n",
    "    Searches for news articles based on actor and recipient, extracts their URLs, \n",
    "    and scrapes the content as plain text after cleaning.\n",
    "    \n",
    "    :param actor: Name of the actor involved in the event.\n",
    "    :param recipient: Name of the recipient involved in the event.\n",
    "    :return: List of dictionaries with article titles, cleaned content, and URLs.\n",
    "    \"\"\"\n",
    "    query = f\"{actor} AND {recipient}\"\n",
    "    api_key = os.getenv(\"NEWS_API_KEY\")\n",
    "    # print(api_key)\n",
    "    url = f\"https://newsapi.org/v2/everything?q={query}&sortBy=publishedAt&apiKey={api_key}\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        articles = response.json().get('articles', [])\n",
    "        \n",
    "        results = []\n",
    "        for article in articles:\n",
    "            article_url = article.get(\"url\")\n",
    "            if not article_url:\n",
    "                continue\n",
    "            \n",
    "            content = scrape_content(article_url)\n",
    "            if content:\n",
    "                results.append({\n",
    "                    \"title\": article.get(\"title\"),\n",
    "                    \"content\": content,\n",
    "                    \"url\": article_url\n",
    "                })\n",
    "        return results\n",
    "    else:\n",
    "        print(\"Error fetching news articles.\")\n",
    "        # print(response.text)\n",
    "        return []\n",
    "\n",
    "def scrape_content(url):\n",
    "    \"\"\"\n",
    "    Scrapes and cleans article content from the given URL.\n",
    "    \n",
    "    :param url: URL of the article.\n",
    "    :return: Cleaned article content as plain text.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Extract all paragraph text as content\n",
    "        paragraphs = soup.find_all('p')\n",
    "        content = ' '.join(p.get_text(strip=True) for p in paragraphs)\n",
    "        \n",
    "        # Basic cleanup for extra spaces\n",
    "        content = ' '.join(content.split())\n",
    "        return content\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Failed to fetch the URL {url}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    actor = \"Arvind Kejriwal\"\n",
    "    recipient = \"Delhi High Court\"\n",
    "    articles = search_and_extract_news(actor, recipient)\n",
    "\n",
    "    for article in articles:\n",
    "        print(f\"Title: {article['title']}\")\n",
    "        print(f\"URL: {article['url']}\")\n",
    "        print(f\"Content: {article['content'][:500]}...\\n\")  # Display first 500 characters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
